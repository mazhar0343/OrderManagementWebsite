"""Core prediction logic for Formula 1 race outcomes using FastF1 data."""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
import json
from pathlib import Path
from typing import Dict, List, Mapping, Optional, Sequence, Tuple
import warnings

import fastf1
import numpy as np
import pandas as pd


SessionLabel = str


@dataclass
class PredictionResult:
    """Container for the prediction output generated by :class:`FastF1RacePredictor`."""

    season: int
    event: str
    sessions_used: Tuple[SessionLabel, ...]
    generated_at: datetime
    table: pd.DataFrame

    def as_dataframe(self) -> pd.DataFrame:
        """Return a defensive copy of the predictions dataframe."""

        return self.table.copy(deep=True)

    def to_dict(self) -> Mapping[str, object]:
        """Serialise the prediction result as a nested mapping."""

        return {
            "season": self.season,
            "event": self.event,
            "sessions_used": list(self.sessions_used),
            "generated_at": self.generated_at.isoformat(),
            "predictions": self.table.to_dict(orient="records"),
        }

    def to_json(self, *, indent: Optional[int] = 2) -> str:
        """Serialise the prediction result as JSON."""

        return json.dumps(self.to_dict(), indent=indent, default=_json_default)

    def save_json(self, output: Path, *, indent: Optional[int] = 2) -> None:
        """Persist the prediction result as JSON."""

        output.parent.mkdir(parents=True, exist_ok=True)
        output.write_text(self.to_json(indent=indent), encoding="utf-8")


def _json_default(value: object) -> object:
    """Default serialiser for JSON outputs."""

    if isinstance(value, (np.floating, np.integer)):
        return value.item()
    if isinstance(value, (datetime, pd.Timestamp)):
        return value.isoformat()
    raise TypeError(f"Object of type {type(value)!r} is not JSON serialisable")


class FastF1RacePredictor:
    """Predict race finishing order using practice and qualifying pace data.

    The predictor collates lap timing information from the specified sessions,
    applies a weighting scheme, and produces a ranked list of drivers for the
    target event. While intentionally simple, this approach provides a
    repeatable baseline that can be enhanced with additional features (tyre
    usage, weather corrections, machine learning models, etc.).
    """

    DEFAULT_SESSION_WEIGHTS: Mapping[SessionLabel, float] = {
        "FP1": 0.15,
        "FP2": 0.25,
        "FP3": 0.2,
        "Q": 0.4,
    }

    SESSION_ALIASES: Mapping[str, SessionLabel] = {
        "P1": "FP1",
        "P2": "FP2",
        "P3": "FP3",
        "QUALI": "Q",
        "QUALIFYING": "Q",
        "SQ": "SQ",
        "SPRINT_QUALIFYING": "SQ",
        "SPRINTSHOOTOUT": "SQ",
        "SPRINT_SHOOTOUT": "SQ",
        "SPRINTRACE": "Sprint",
        "SPRINT": "Sprint",
    }

    def __init__(
        self,
        cache_dir: str | Path = "cache",
        *,
        session_weights: Optional[Mapping[SessionLabel, float]] = None,
        min_laps: int = 5,
        verbose: bool = False,
    ) -> None:
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        fastf1.Cache.enable_cache(str(self.cache_dir))

        self.session_weights: Dict[SessionLabel, float] = self._normalise_weights(
            session_weights or self.DEFAULT_SESSION_WEIGHTS
        )
        self.min_laps = min_laps
        self.verbose = verbose

    def predict(
        self,
        season: int,
        event: str | int,
        *,
        sessions: Optional[Sequence[SessionLabel]] = None,
    ) -> PredictionResult:
        """Create a race finishing order prediction for a given event."""

        target_sessions = self._resolve_sessions(sessions)

        aggregated: List[Tuple[SessionLabel, pd.DataFrame]] = []
        driver_metadata: Dict[str, Dict[str, object]] = {}
        sessions_used: List[SessionLabel] = []

        for label in target_sessions:
            try:
                session = fastf1.get_session(season, event, label)
                session.load(laps=True, telemetry=False, weather=False, messages=False)
            except Exception as exc:  # pragma: no cover - network dependent
                warnings.warn(
                    f"Skipping session '{label}' due to load error: {exc}",
                    RuntimeWarning,
                    stacklevel=2,
                )
                continue

            summary = self._summarise_session(session)
            if summary.empty:
                if self.verbose:
                    warnings.warn(
                        f"No lap timing data for session '{label}'.", RuntimeWarning, stacklevel=2
                    )
                continue

            aggregated.append((label, summary))
            sessions_used.append(label)
            driver_metadata.update(self._extract_driver_metadata(session))

        if not aggregated:
            raise RuntimeError(
                "Unable to build prediction: no session data was loaded successfully."
            )

        feature_table = self._build_feature_table(aggregated)
        enriched = self._attach_driver_metadata(feature_table, driver_metadata)
        scored = self._score_predictions(enriched, sessions_used)

        event_name = str(event)
        try:
            # Attempt to use the official event name for readability.
            schedule = fastf1.get_event(season, event)
            if schedule is not None:
                event_name = schedule.EventName
        except Exception:
            pass

        return PredictionResult(
            season=season,
            event=event_name,
            sessions_used=tuple(sessions_used),
            generated_at=datetime.utcnow(),
            table=scored,
        )

    # ------------------------------------------------------------------
    # Internal helpers

    def _resolve_sessions(
        self, sessions: Optional[Sequence[SessionLabel]]
    ) -> Tuple[SessionLabel, ...]:
        if sessions:
            resolved = []
            for label in sessions:
                resolved.append(self._normalise_session_label(label))
        else:
            resolved = list(self.session_weights.keys())
        # Remove duplicates while preserving order
        seen: set[str] = set()
        ordered: List[SessionLabel] = []
        for label in resolved:
            if label not in seen:
                seen.add(label)
                ordered.append(label)
        return tuple(ordered)

    def _normalise_session_label(self, label: SessionLabel) -> SessionLabel:
        canonical = label.upper().replace(" ", "").replace("-", "")
        return self.SESSION_ALIASES.get(canonical, canonical)

    def _normalise_weights(
        self, weights: Mapping[SessionLabel, float]
    ) -> Dict[SessionLabel, float]:
        positive = {self._normalise_session_label(k): float(v) for k, v in weights.items() if v > 0}
        total = sum(positive.values())
        if total <= 0:
            raise ValueError("Session weights must contain at least one positive entry")
        return {label: value / total for label, value in positive.items()}

    def _summarise_session(self, session: fastf1.core.Session) -> pd.DataFrame:
        laps = session.laps
        if laps is None or laps.empty:
            return pd.DataFrame(columns=[
                "driver_number",
                "best_lap_seconds",
                "median_lap_seconds",
                "mean_lap_seconds",
                "lap_count",
                "long_run_seconds",
            ])

        laps = laps.copy()
        laps = laps.loc[laps["LapTime"].notna()].copy()
        if laps.empty:
            return pd.DataFrame(columns=[
                "driver_number",
                "best_lap_seconds",
                "median_lap_seconds",
                "mean_lap_seconds",
                "lap_count",
                "long_run_seconds",
            ])

        laps["lap_seconds"] = laps["LapTime"].dt.total_seconds()

        accurate = laps.loc[laps["IsAccurate"].fillna(True)].copy()
        if accurate.empty:
            accurate = laps

        grouped = accurate.groupby("DriverNumber", observed=True)
        summary = grouped.agg(
            best_lap_seconds=("lap_seconds", "min"),
            median_lap_seconds=("lap_seconds", "median"),
            mean_lap_seconds=("lap_seconds", "mean"),
            lap_count=("lap_seconds", "count"),
        )

        long_run = accurate.loc[accurate["TyreLife"].fillna(0) >= 5]
        if long_run.empty:
            long_run = accurate
        long_summary = long_run.groupby("DriverNumber", observed=True)["lap_seconds"].median()
        summary = summary.merge(
            long_summary.rename("long_run_seconds"),
            left_index=True,
            right_index=True,
            how="left",
        )

        summary.reset_index(inplace=True)
        summary.rename(columns={"DriverNumber": "driver_number"}, inplace=True)
        summary["driver_number"] = summary["driver_number"].astype(str)
        summary["low_lap_warning"] = summary["lap_count"] < self.min_laps

        return summary

    def _extract_driver_metadata(
        self, session: fastf1.core.Session
    ) -> Dict[str, Dict[str, object]]:
        metadata: Dict[str, Dict[str, object]] = {}

        for driver_number in session.drivers or []:
            try:
                info = session.get_driver(driver_number)
            except Exception:  # pragma: no cover - defensive
                continue

            if info is None:
                continue

            number = str(info.get("DriverNumber", driver_number))
            full_name = (
                info.get("FullName")
                or " ".join(filter(None, [info.get("FirstName"), info.get("LastName")])).strip()
                or info.get("BroadcastName", "").strip()
            )
            code = (info.get("Abbreviation") or info.get("BroadcastName", " ")[:3]).strip()
            team = info.get("TeamName") or info.get("Team") or ""

            metadata[number] = {
                "driver_number": number,
                "driver": full_name or f"Driver {number}",
                "code": code or number,
                "team": team,
            }

        return metadata

    def _build_feature_table(
        self, aggregated: Sequence[Tuple[SessionLabel, pd.DataFrame]]
    ) -> pd.DataFrame:
        frames: List[pd.DataFrame] = []
        for label, frame in aggregated:
            renamed = frame.rename(
                columns={
                    column: column if column == "driver_number" else f"{label}_{column}"
                    for column in frame.columns
                }
            )
            frames.append(renamed)

        base = frames[0]
        for frame in frames[1:]:
            base = base.merge(frame, on="driver_number", how="outer")

        base["driver_number"] = base["driver_number"].astype(str)
        return base

    def _attach_driver_metadata(
        self,
        features: pd.DataFrame,
        metadata: Mapping[str, Mapping[str, object]],
    ) -> pd.DataFrame:
        if not metadata:
            features["driver"] = "Unknown"
            features["code"] = features["driver_number"]
            features["team"] = ""
            return features

        meta_frame = pd.DataFrame.from_dict(metadata, orient="index")
        meta_frame.reset_index(drop=True, inplace=True)
        meta_frame["driver_number"] = meta_frame["driver_number"].astype(str)

        merged = features.merge(meta_frame, on="driver_number", how="left")
        merged["driver"] = merged["driver"].fillna("Unknown")
        merged["code"] = merged["code"].fillna(merged["driver_number"])
        merged["team"] = merged["team"].fillna("")
        return merged

    def _score_predictions(
        self,
        df: pd.DataFrame,
        sessions_used: Sequence[SessionLabel],
    ) -> pd.DataFrame:
        scored = df.copy()
        scored["score"] = 0.0

        for label in sessions_used:
            weight = self.session_weights.get(label, 0.0)
            if weight <= 0:
                continue

            best_col = f"{label}_best_lap_seconds"
            median_col = f"{label}_median_lap_seconds"
            long_col = f"{label}_long_run_seconds"
            laps_col = f"{label}_lap_count"
            low_lap_col = f"{label}_low_lap_warning"

            best_component = np.zeros(len(scored))
            if best_col in scored:
                best_series = scored[best_col]
                available = best_series.dropna()
                if not available.empty:
                    fastest = available.min()
                    best_component = np.where(
                        best_series.notna(),
                        fastest / best_series,
                        0.0,
                    )

            median_component = np.zeros(len(scored))
            if median_col in scored:
                median_series = scored[median_col]
                available = median_series.dropna()
                if not available.empty:
                    baseline = available.min()
                    median_component = np.where(
                        median_series.notna(),
                        baseline / median_series,
                        0.0,
                    )

            combined = 0.6 * best_component + 0.4 * median_component

            if long_col in scored:
                long_series = scored[long_col]
                available = long_series.dropna()
                if not available.empty:
                    base_long = available.min()
                    long_component = np.where(
                        long_series.notna(),
                        base_long / long_series,
                        0.0,
                    )
                    combined = 0.7 * combined + 0.3 * long_component

            contribution = weight * combined
            scored[f"{label}_pace_score"] = contribution
            scored["score"] += contribution

            if laps_col in scored:
                laps_series = scored[laps_col]
                available = laps_series.dropna()
                if not available.empty:
                    lap_bonus = np.where(
                        laps_series.notna(),
                        laps_series / available.max(),
                        0.0,
                    )
                    bonus = weight * 0.05 * lap_bonus
                    scored[f"{label}_lap_bonus"] = bonus
                    scored["score"] += bonus

            if low_lap_col in scored:
                low_lap_penalty = np.where(
                    scored[low_lap_col].fillna(False),
                    weight * 0.03,
                    0.0,
                )
                scored[f"{label}_lap_penalty"] = low_lap_penalty
                scored["score"] -= low_lap_penalty

        max_score = scored["score"].max()
        min_score = scored["score"].min()
        if np.isclose(max_score, min_score):
            scored["confidence"] = 1.0
            scored["predicted_gap_seconds"] = 0.0
        else:
            scored["confidence"] = (scored["score"] - min_score) / (max_score - min_score)
            scored["predicted_gap_seconds"] = (max_score - scored["score"]) / max_score * 20.0

        scored["confidence"] = scored["confidence"].clip(0, 1)

        # Track which sessions were missing for each driver for transparency.
        def missing_sessions(row: pd.Series) -> List[str]:
            missing: List[str] = []
            for label in sessions_used:
                column = f"{label}_best_lap_seconds"
                if column not in row or pd.isna(row[column]):
                    missing.append(label)
            return missing

        scored["missing_sessions"] = scored.apply(missing_sessions, axis=1)

        scored.sort_values(by=["score", "driver_number"], ascending=[False, True], inplace=True)
        scored.reset_index(drop=True, inplace=True)
        scored["predicted_position"] = np.arange(1, len(scored) + 1)

        cols = [
            "predicted_position",
            "driver_number",
            "code",
            "driver",
            "team",
            "score",
            "confidence",
            "predicted_gap_seconds",
            "missing_sessions",
        ]
        # Append metric columns for transparency without altering the leading order.
        metric_columns = [
            column
            for column in scored.columns
            if column not in cols
        ]
        ordered_columns = cols + metric_columns
        scored = scored.loc[:, ordered_columns]

        return scored

